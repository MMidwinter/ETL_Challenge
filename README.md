<h1> ETL_Challenge</h1>
#This is where we will be posting instruction on how to generate our tables. 

<h1>Process notes</h1>

Clone this repo to your desktop; it will contain the three necessary source csvs to produce the database.

Launch a jupyter notebook from the repo and open {FILE NAME}.
Notes on how csvs were cleaned and issues resolved in dataframes:
* GoodBooks csv 
  * was not encoded in UTF-8 and had to be specified to be encoded in Latin1. 
  * This document was also separated by semicolons vs commas
  * There were additional errors in rows, so additional code was included to skip those rows when assembling the cv
* BookCrossing Books csv
  * Rating counts were dropped as that data can be generated by joining the book table and ratings table from the database.  Additional space can be conserved by excluding those calculations and allowing those interacting with the database to form their own analysis.
* Book_crossing_data
  * NaNs dropped before setting the index as there was an absent publication year for BossyPants by Tina Fey. We also dropped NaNs from good_books_ratings to avoid duplicate ISBN issue in our index and primary key column.
* Book_crossing_ratings
  * The dataframe presented a duplicate user_id and book_id combination, so we returned to the dataframe only keep the first appearance of that combination so that the user_id column remained a unique identifier.
* Good_books_ratings
  * Dropped NaNs and duplicates present in the isbn column before setting as the index
* Column names were conformed to the match across dataframes and tables
* Each dataframe has the isbn set as the index, save for the good_books_rating dataframe where the user_id is the unique identifier used as the index. These indexes are used as the primary keys in the sql tables

After running the code to clean the csvs, open PGAdmin to access Postgress.
Log in and create a database called bookrating_db.
Create three tables as described below using the included table_schema.sql:
* Good_books_ratings
    * Isbn TEXT primary key
    * Book_rating INT
* book_crossing_ratings
    * Usesr_id INT PRIMARY KEY
    * Book_id INT PRIMARY KEY
    * Book_rating INT
* Book_crossing_data
    * Isbn TEXT PRIMARY KEY
    * Book_id INT
    * Authors TEXT
    * Original_publication_year INT
    * Original_title TEXT


This database is intended to be built in SQL using Postgres and PGAdmin.  Please note that the code following the cleaning of the csv files includes a username and password requirement to communicate with Postgres,  Before running those cells, be sure to enter your own username and password before running the code.

Loading the data into the dataframe
* Book_crossing_ratings is a large dataset and may take longer than the other two to run when uploading data to the database.
